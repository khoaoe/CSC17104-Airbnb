├── .env.example
├── .gitignore
├── README.md
├── data
    ├── processed
    │   └── airbnb_2019_preprocessed.npz
    └── raw
    │   └── New_York_City_.png
├── notebooks
    ├── 01_data_exploration.ipynb
    ├── 02_preprocessing.ipynb
    └── 03_modeling.ipynb
├── requirements.txt
├── scripts
    └── setup_secrets.sh
└── src
    ├── __init__.py
    ├── data_processing.py
    ├── models.py
    └── visualization.py


/.env.example:
--------------------------------------------------------------------------------
1 | # sao chép file này thành .env và điền giá trị thật 
2 | # key cho Kaggle API (thay thế cho kaggle.json)
3 | KAGGLE_USERNAME=your_username
4 | KAGGLE_KEY=your_api_key


--------------------------------------------------------------------------------
/.gitignore:
--------------------------------------------------------------------------------
 1 | # secrets
 2 | .env
 3 | !.env.example
 4 | .kaggle/
 5 | *.txt
 6 | *.csv
 7 | /.config
 8 | /notebooks/.ipynb_checkpoints
 9 | *.pyc
10 | 


--------------------------------------------------------------------------------
/README.md:
--------------------------------------------------------------------------------
 1 | ## Secrets (.env) & Kaggle API 
 2 | 
 3 | * Tạo secrets bằng `.env`: copy `.env.example` → đổi tên thành `.env` và điền `KAGGLE_USERNAME`, `KAGGLE_KEY`.
 4 | * Thiết lập trên Linux:
 5 | 
 6 |   ```bash
 7 |   bash scripts/setup_secrets.sh
 8 |   ```
 9 | 
10 | * Ưu tiên `~/.kaggle/kaggle.json`; nếu chưa có, script sẽ tạo từ `.env`.
11 | * Kaggle API cần `~/.kaggle/kaggle.json` **hoặc** biến môi trường `KAGGLE_USERNAME`/`KAGGLE_KEY`.
12 | 
13 | ---
14 | 
15 | ## Môi trường ảo
16 | 
17 | 1. Cài venv (nếu chưa có):
18 | 
19 | ```bash
20 | sudo apt update && sudo apt install -y python3 python3-pip python3-venv
21 | ```
22 | 
23 | 2. Tạo & kích hoạt môi trường ảo trong thư mục dự án:
24 | 
25 | ```bash
26 | python3 -m venv .venv
27 | source .venv/bin/activate
28 | ```
29 | 
30 | 3. Cài dependencies từ `requirements.txt`:
31 | 
32 | ```bash
33 | pip install --upgrade pip
34 | pip install -r requirements.txt
35 | python -m pip install -U kaggle # kaggle-cli để tải dataset
36 | chmod 600 ~/.kaggle/kaggle.json # cấp quyền
37 | ```
38 | 
39 | 4. Thoát môi trường khi xong:
40 | 
41 | ```bash
42 | deactivate
43 | ```
44 | 
45 | **Ghi chú**
46 | 
47 | * Thêm `.venv/` vào `.gitignore`.
48 | * Nếu cài thêm thư viện mới, cập nhật:
49 | 
50 | ```bash
51 | pip freeze > requirements.txt
52 | ```
53 | 


--------------------------------------------------------------------------------
/data/processed/airbnb_2019_preprocessed.npz:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/khoaoe/hcmus-csc17104-airbnb-data-analysis/d1a2c486c0d19547b61c42b47bf87ca697883cba/data/processed/airbnb_2019_preprocessed.npz


--------------------------------------------------------------------------------
/data/raw/New_York_City_.png:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/khoaoe/hcmus-csc17104-airbnb-data-analysis/d1a2c486c0d19547b61c42b47bf87ca697883cba/data/raw/New_York_City_.png


--------------------------------------------------------------------------------
/notebooks/01_data_exploration.ipynb:
--------------------------------------------------------------------------------
  1 | {
  2 |  "cells": [
  3 |   {
  4 |    "cell_type": "markdown",
  5 |    "id": "607fb287",
  6 |    "metadata": {},
  7 |    "source": [
  8 |     "# 01 — Data Exploration \n",
  9 |     "- Tải `AB_NYC_2019.csv` (nếu chưa có) bằng Kaggle CLI\n",
 10 |     "- Đọc CSV *không dùng pandas* (chỉ csv + numpy) qua `src.data_processing`\n",
 11 |     "- In report: shape, cột quan trọng, unique của nhóm/kind, NA, phạm vi availability_365"
 12 |    ]
 13 |   },
 14 |   {
 15 |    "cell_type": "code",
 16 |    "execution_count": 1,
 17 |    "id": "8520abc1",
 18 |    "metadata": {},
 19 |    "outputs": [],
 20 |    "source": [
 21 |     "# thêm project root (thư mục chứa 'src/') vào sys.path\n",
 22 |     "from pathlib import Path\n",
 23 |     "import sys\n",
 24 |     "\n",
 25 |     "ROOT = Path.cwd()\n",
 26 |     "while not (ROOT / \"src\").is_dir() and ROOT.parent != ROOT:\n",
 27 |     "    ROOT = ROOT.parent\n",
 28 |     "\n",
 29 |     "sys.path.append(str(ROOT))"
 30 |    ]
 31 |   },
 32 |   {
 33 |    "cell_type": "markdown",
 34 |    "id": "cb3abe30",
 35 |    "metadata": {},
 36 |    "source": [
 37 |     "## 1. Tải & kiểm tra dữ liệu"
 38 |    ]
 39 |   },
 40 |   {
 41 |    "cell_type": "code",
 42 |    "execution_count": 2,
 43 |    "id": "9e44c3cd",
 44 |    "metadata": {},
 45 |    "outputs": [
 46 |     {
 47 |      "name": "stdout",
 48 |      "output_type": "stream",
 49 |      "text": [
 50 |       "Shape: 48895 hang x 16 cot\n",
 51 |       "Important Columns: price, minimum_nights, number_of_reviews, reviews_per_month, calculated_host_listings_count, availability_365, latitude, longitude\n",
 52 |       "neighbourhood_group: 5 groups -> Bronx, Brooklyn, Manhattan, Queens\n",
 53 |       "room_type: 3 types -> Entire home/apt, Private room, Shared room\n",
 54 |       "availability_365 out of [0, 365]: 0\n",
 55 |       "reviews_per_month NA: 10052\n",
 56 |       "last_review NA: 10052\n"
 57 |      ]
 58 |     }
 59 |    ],
 60 |    "source": [
 61 |     "from src.data_processing import load_and_check \n",
 62 |     "\n",
 63 |     "report = load_and_check(root=str(ROOT / \"data\"))"
 64 |    ]
 65 |   },
 66 |   {
 67 |    "cell_type": "markdown",
 68 |    "id": "68633c16",
 69 |    "metadata": {},
 70 |    "source": [
 71 |     "## 2. Đọc dữ liệu bằng NumPy"
 72 |    ]
 73 |   },
 74 |   {
 75 |    "cell_type": "code",
 76 |    "execution_count": 3,
 77 |    "id": "3aabc1b0",
 78 |    "metadata": {},
 79 |    "outputs": [
 80 |     {
 81 |      "name": "stdout",
 82 |      "output_type": "stream",
 83 |      "text": [
 84 |       "Số cột: 16\n",
 85 |       "Các cột số có: ['latitude', 'longitude', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
 86 |       "Các cột text có: ['id', 'name', 'host_id', 'host_name', 'neighbourhood_group', 'neighbourhood', 'room_type', 'last_review'] ...\n"
 87 |      ]
 88 |     }
 89 |    ],
 90 |    "source": [
 91 |     "from src.data_processing import ensure_data_dirs, load_airbnb_numpy\n",
 92 |     "\n",
 93 |     "# Lấy đường dẫn CSV và load thành dict {'header', 'text', 'num'}\n",
 94 |     "dirs = ensure_data_dirs(root=str(ROOT / \"data\"))\n",
 95 |     "csv_path = dirs[\"raw\"] / \"AB_NYC_2019.csv\"\n",
 96 |     "\n",
 97 |     "data = load_airbnb_numpy(csv_path)\n",
 98 |     "header = data[\"header\"]\n",
 99 |     "num = data[\"num\"]   \n",
100 |     "text = data[\"text\"] \n",
101 |     "\n",
102 |     "print(\"Số cột:\", len(header))\n",
103 |     "print(\"Các cột số có:\", list(num.keys()))\n",
104 |     "print(\"Các cột text có:\", list(text.keys())[:8], \"...\")"
105 |    ]
106 |   },
107 |   {
108 |    "cell_type": "markdown",
109 |    "id": "aabb2fd1",
110 |    "metadata": {},
111 |    "source": [
112 |     "## 3. Thống kê mô tả"
113 |    ]
114 |   },
115 |   {
116 |    "cell_type": "code",
117 |    "execution_count": 4,
118 |    "id": "fcb32399",
119 |    "metadata": {},
120 |    "outputs": [
121 |     {
122 |      "name": "stdout",
123 |      "output_type": "stream",
124 |      "text": [
125 |       "[price] n=48895 miss=0 | mean=152.72 std=240.15 | min=0.00 p25=69.00 p50=106.00 p75=175.00 max=10000.00\n",
126 |       "[minimum_nights] n=48895 miss=0 | mean=7.03 std=20.51 | min=1.00 p25=1.00 p50=3.00 p75=5.00 max=1250.00\n",
127 |       "[number_of_reviews] n=48895 miss=0 | mean=23.27 std=44.55 | min=0.00 p25=1.00 p50=5.00 p75=24.00 max=629.00\n",
128 |       "[reviews_per_month] n=48895 miss=10052 | mean=1.37 std=1.68 | min=0.01 p25=0.19 p50=0.72 p75=2.02 max=58.50\n",
129 |       "[calculated_host_listings_count] n=48895 miss=0 | mean=7.14 std=32.95 | min=1.00 p25=1.00 p50=1.00 p75=2.00 max=327.00\n",
130 |       "[availability_365] n=48895 miss=0 | mean=112.78 std=131.62 | min=0.00 p25=0.00 p50=45.00 p75=227.00 max=365.00\n",
131 |       "[latitude] n=48895 miss=0 | mean=40.73 std=0.05 | min=40.50 p25=40.69 p50=40.72 p75=40.76 max=40.91\n",
132 |       "[longitude] n=48895 miss=0 | mean=-73.95 std=0.05 | min=-74.24 p25=-73.98 p50=-73.96 p75=-73.94 max=-73.71\n"
133 |      ]
134 |     }
135 |    ],
136 |    "source": [
137 |     "import numpy as np\n",
138 |     "\n",
139 |     "# Hàm mô tả cột số, bỏ qua NaN bằng np.nan* (ổn định và gọn)\n",
140 |     "def describe_numeric(arr: np.ndarray) -> dict:\n",
141 |     "    # arr có thể chứa NaN (đặc biệt reviews_per_month)\n",
142 |     "    return {\n",
143 |     "        \"n\": int(arr.size),\n",
144 |     "        \"missing\": int(np.isnan(arr).sum()) if arr.dtype.kind in \"fc\" else 0,\n",
145 |     "        \"mean\": float(np.nanmean(arr)),\n",
146 |     "        \"std\": float(np.nanstd(arr)),\n",
147 |     "        \"min\": float(np.nanmin(arr)),\n",
148 |     "        \"p25\": float(np.nanpercentile(arr, 25)),\n",
149 |     "        \"p50\": float(np.nanmedian(arr)),\n",
150 |     "        \"p75\": float(np.nanpercentile(arr, 75)),\n",
151 |     "        \"max\": float(np.nanmax(arr)),\n",
152 |     "    }\n",
153 |     "\n",
154 |     "# Các cột số chính để mô tả\n",
155 |     "KEY_NUM_COLS = [\n",
156 |     "    \"price\",\n",
157 |     "    \"minimum_nights\",\n",
158 |     "    \"number_of_reviews\",\n",
159 |     "    \"reviews_per_month\",\n",
160 |     "    \"calculated_host_listings_count\",\n",
161 |     "    \"availability_365\",\n",
162 |     "    \"latitude\",\n",
163 |     "    \"longitude\",\n",
164 |     "]\n",
165 |     "\n",
166 |     "desc = {}\n",
167 |     "for col in KEY_NUM_COLS:\n",
168 |     "    if col in num:\n",
169 |     "        desc[col] = describe_numeric(num[col])\n",
170 |     "\n",
171 |     "# In gọn kết quả\n",
172 |     "for k, v in desc.items():\n",
173 |     "    print(f\"[{k}] n={v['n']} miss={v['missing']} | \"\n",
174 |     "          f\"mean={v['mean']:.2f} std={v['std']:.2f} | \"\n",
175 |     "          f\"min={v['min']:.2f} p25={v['p25']:.2f} p50={v['p50']:.2f} \"\n",
176 |     "          f\"p75={v['p75']:.2f} max={v['max']:.2f}\")\n"
177 |    ]
178 |   },
179 |   {
180 |    "cell_type": "markdown",
181 |    "id": "53770a99",
182 |    "metadata": {},
183 |    "source": [
184 |     "## 4. Thống kê nhanh cho cột phân loại"
185 |    ]
186 |   },
187 |   {
188 |    "cell_type": "code",
189 |    "execution_count": 5,
190 |    "id": "07c0c0bd",
191 |    "metadata": {},
192 |    "outputs": [
193 |     {
194 |      "name": "stdout",
195 |      "output_type": "stream",
196 |      "text": [
197 |       "\n",
198 |       "Top neighbourhood_group:\n",
199 |       "  Manhattan: 21661\n",
200 |       "  Brooklyn: 20104\n",
201 |       "  Queens: 5666\n",
202 |       "  Bronx: 1091\n",
203 |       "  Staten Island: 373\n",
204 |       "\n",
205 |       "Top room_type:\n",
206 |       "  Entire home/apt: 25409\n",
207 |       "  Private room: 22326\n",
208 |       "  Shared room: 1160\n",
209 |       "\n",
210 |       "Top neighbourhood:\n",
211 |       "  Williamsburg: 3920\n",
212 |       "  Bedford-Stuyvesant: 3714\n",
213 |       "  Harlem: 2658\n",
214 |       "  Bushwick: 2465\n",
215 |       "  Upper West Side: 1971\n",
216 |       "  Hell's Kitchen: 1958\n",
217 |       "  East Village: 1853\n",
218 |       "  Upper East Side: 1798\n"
219 |      ]
220 |     }
221 |    ],
222 |    "source": [
223 |     "def top_counts(arr: np.ndarray, topk: int = 10):\n",
224 |     "    # Đếm tần suất bằng np.unique(return_counts=True), không dùng pandas\n",
225 |     "    vals, cnts = np.unique(arr, return_counts=True)\n",
226 |     "    order = np.argsort(-cnts)  # tần suất giảm dần\n",
227 |     "    vals, cnts = vals[order], cnts[order]\n",
228 |     "    k = min(topk, vals.size)\n",
229 |     "    return list(zip(vals[:k].tolist(), cnts[:k].tolist()))\n",
230 |     "\n",
231 |     "cat_cols = [\"neighbourhood_group\", \"room_type\", \"neighbourhood\"]\n",
232 |     "for c in cat_cols:\n",
233 |     "    if c in text:\n",
234 |     "        print(f\"\\nTop {c}:\")\n",
235 |     "        for v, ct in top_counts(text[c], topk=8):\n",
236 |     "            print(f\"  {v}: {ct}\")\n"
237 |    ]
238 |   },
239 |   {
240 |    "cell_type": "markdown",
241 |    "id": "95a19a23",
242 |    "metadata": {},
243 |    "source": [
244 |     "## 5. Plot"
245 |    ]
246 |   },
247 |   {
248 |    "cell_type": "code",
249 |    "execution_count": null,
250 |    "id": "5efbbf58",
251 |    "metadata": {},
252 |    "outputs": [],
253 |    "source": [
254 |     "from matplotlib import pyplot as plt\n",
255 |     "from src import plot_price_hist_log, plot_min_nights_hist, plot_scatter_map\n",
256 |     "\n",
257 |     "plt.rcParams[\"figure.dpi\"] = 110\n",
258 |     "\n",
259 |     "if \"price\" in num:\n",
260 |     "    plot_price_hist_log(num[\"price\"])\n",
261 |     "\n",
262 |     "if \"minimum_nights\" in num:\n",
263 |     "    plot_min_nights_hist(num[\"minimum_nights\"])\n",
264 |     "\n",
265 |     "if {\"longitude\", \"latitude\"}.issubset(num.keys()) and \"neighbourhood_group\" in text:\n",
266 |     "    plot_scatter_map(num[\"longitude\"], num[\"latitude\"], text[\"neighbourhood_group\"])\n"
267 |    ]
268 |   }
269 |  ],
270 |  "metadata": {
271 |   "kernelspec": {
272 |    "display_name": "Python 3 (ipykernel)",
273 |    "language": "python",
274 |    "name": "python3"
275 |   },
276 |   "language_info": {
277 |    "codemirror_mode": {
278 |     "name": "ipython",
279 |     "version": 3
280 |    },
281 |    "file_extension": ".py",
282 |    "mimetype": "text/x-python",
283 |    "name": "python",
284 |    "nbconvert_exporter": "python",
285 |    "pygments_lexer": "ipython3",
286 |    "version": "3.11.5"
287 |   }
288 |  },
289 |  "nbformat": 4,
290 |  "nbformat_minor": 5
291 | }


--------------------------------------------------------------------------------
/notebooks/02_preprocessing.ipynb:
--------------------------------------------------------------------------------
  1 | {
  2 |  "cells": [
  3 |   {
  4 |    "cell_type": "markdown",
  5 |    "id": "daa229fe",
  6 |    "metadata": {},
  7 |    "source": [
  8 |     "## 1. Khởi tạo & import"
  9 |    ]
 10 |   },
 11 |   {
 12 |    "cell_type": "code",
 13 |    "execution_count": 1,
 14 |    "id": "ca0607e3",
 15 |    "metadata": {},
 16 |    "outputs": [],
 17 |    "source": [
 18 |     "# thêm project root (thư mục chứa 'src/') vào sys.path\n",
 19 |     "from pathlib import Path\n",
 20 |     "import sys\n",
 21 |     "\n",
 22 |     "ROOT = Path.cwd()\n",
 23 |     "while not (ROOT / \"src\").is_dir() and ROOT.parent != ROOT:\n",
 24 |     "    ROOT = ROOT.parent\n",
 25 |     "\n",
 26 |     "sys.path.append(str(ROOT))"
 27 |    ]
 28 |   },
 29 |   {
 30 |    "cell_type": "markdown",
 31 |    "id": "09e69d4b",
 32 |    "metadata": {},
 33 |    "source": [
 34 |     "## 2. Đọc dữ liệu (CSV => NumPy)"
 35 |    ]
 36 |   },
 37 |   {
 38 |    "cell_type": "markdown",
 39 |    "id": "fde20472",
 40 |    "metadata": {},
 41 |    "source": [
 42 |     "## 3. Hàm helpers thuần NumPy "
 43 |    ]
 44 |   },
 45 |   {
 46 |    "cell_type": "markdown",
 47 |    "id": "1c1d7665",
 48 |    "metadata": {},
 49 |    "source": [
 50 |     "## 4. Làm sạch dữ liệu"
 51 |    ]
 52 |   },
 53 |   {
 54 |    "cell_type": "markdown",
 55 |    "id": "79170bdf",
 56 |    "metadata": {},
 57 |    "source": [
 58 |     "## 5. Tạo đặc trưng "
 59 |    ]
 60 |   },
 61 |   {
 62 |    "cell_type": "markdown",
 63 |    "id": "f98f02fe",
 64 |    "metadata": {},
 65 |    "source": [
 66 |     "## 6. Lưu output .npz để dùng cho 03_modeling"
 67 |    ]
 68 |   },
 69 |   {
 70 |    "cell_type": "markdown",
 71 |    "id": "29ff8584",
 72 |    "metadata": {},
 73 |    "source": [
 74 |     "## 7) Sanity check "
 75 |    ]
 76 |   },
 77 |   {
 78 |    "cell_type": "code",
 79 |    "execution_count": null,
 80 |    "metadata": {},
 81 |    "outputs": [],
 82 |    "source": [
 83 |     "from src import preprocess_and_save\n",
 84 |     "out_path = preprocess_and_save(root=\"../data\", out_name=\"airbnb_2019_preprocessed.npz\")\n",
 85 |     "print(\"Saved ->\", out_path)\n"
 86 |    ]
 87 |   },
 88 |   {
 89 |    "cell_type": "code",
 90 |    "execution_count": null,
 91 |    "metadata": {},
 92 |    "outputs": [],
 93 |    "source": [
 94 |     "import numpy as np\n",
 95 |     "\n",
 96 |     "bundle = np.load(out_path, allow_pickle=True)\n",
 97 |     "X, y = bundle[\"X\"], bundle[\"y\"]\n",
 98 |     "assert np.isfinite(X).all(), \"X co NaN/Inf\"\n",
 99 |     "assert np.isfinite(y).all(), \"y co NaN/Inf\"\n",
100 |     "print(\"Shapes:\", X.shape, y.shape)\n"
101 |    ]
102 |   }
103 |  ],
104 |  "metadata": {
105 |   "kernelspec": {
106 |    "display_name": "Python 3 (ipykernel)",
107 |    "language": "python",
108 |    "name": "python3"
109 |   },
110 |   "language_info": {
111 |    "codemirror_mode": {
112 |     "name": "ipython",
113 |     "version": 3
114 |    },
115 |    "file_extension": ".py",
116 |    "mimetype": "text/x-python",
117 |    "name": "python",
118 |    "nbconvert_exporter": "python",
119 |    "pygments_lexer": "ipython3",
120 |    "version": "3.11.5"
121 |   }
122 |  },
123 |  "nbformat": 4,
124 |  "nbformat_minor": 5
125 | }


--------------------------------------------------------------------------------
/notebooks/03_modeling.ipynb:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/khoaoe/hcmus-csc17104-airbnb-data-analysis/d1a2c486c0d19547b61c42b47bf87ca697883cba/notebooks/03_modeling.ipynb


--------------------------------------------------------------------------------
/requirements.txt:
--------------------------------------------------------------------------------
1 | numpy>=1.24
2 | matplotlib>=3.7


--------------------------------------------------------------------------------
/scripts/setup_secrets.sh:
--------------------------------------------------------------------------------
 1 | #!/usr/bin/env bash
 2 | set -euo pipefail
 3 | # Đọc biến từ .env nếu có (định dạng KEY=VALUE, không có dấu nháy)
 4 | if [ -f ".env" ]; then
 5 |   # shellcheck disable=SC2046
 6 |   export $(grep -E '^[A-Za-z_][A-Za-z0-9_]*=' .env | xargs)
 7 | fi
 8 | 
 9 | # Tạo kaggle.json từ env nếu người dùng không đặt sẵn tại ~/.kaggle/kaggle.json
10 | KAGGLE_DIR="${HOME}/.kaggle"
11 | KAGGLE_JSON="${KAGGLE_DIR}/kaggle.json"
12 | mkdir -p "${KAGGLE_DIR}"
13 | if [ ! -f "${KAGGLE_JSON}" ] && [ -n "${KAGGLE_USERNAME:-}" ] && [ -n "${KAGGLE_KEY:-}" ]; then
14 |   # Kaggle API yêu cầu file JSON đúng schema {username, key}
15 |   cat > "${KAGGLE_JSON}" <<EOF
16 | {"username":"${KAGGLE_USERNAME}","key":"${KAGGLE_KEY}"}
17 | EOF
18 |   chmod 600 "${KAGGLE_JSON}"
19 |   echo "[INFO] Tạo ${KAGGLE_JSON} từ .env"
20 | fi
21 | 
22 | # Nếu vẫn không có file và không có biến, nhắc người dùng
23 | if [ ! -f "${KAGGLE_JSON}" ] && { [ -z "${KAGGLE_USERNAME:-}" ] || [ -z "${KAGGLE_KEY:-}" ]; }; then
24 |   echo "[ERROR] Thiếu thông tin Kaggle. Tạo ~/.kaggle/kaggle.json hoặc khai báo KAGGLE_USERNAME/KAGGLE_KEY trong .env" >&2
25 |   exit 1
26 | fi
27 | echo "[OK] Secrets sẵn sàng (Kaggle API)."


--------------------------------------------------------------------------------
/src/__init__.py:
--------------------------------------------------------------------------------
 1 | from .data_processing import (
 2 |     basic_checks,
 3 |     build_features,
 4 |     clip_outliers_percentile,
 5 |     ensure_data_dirs,
 6 |     kaggle_download_if_needed,
 7 |     load_airbnb_numpy,
 8 |     load_and_check,
 9 |     nonempty_mask,
10 |     one_hot,
11 |     preprocess_and_save,
12 |     safe_log1p,
13 |     PreprocessBundle,
14 |     PreprocessConfig,
15 | )
16 | from .visualization import (
17 |     plot_min_nights_hist,
18 |     plot_price_hist_log,
19 |     plot_scatter_map,
20 | )
21 | 
22 | __all__ = [
23 |     "ensure_data_dirs",
24 |     "kaggle_download_if_needed",
25 |     "load_airbnb_numpy",
26 |     "basic_checks",
27 |     "load_and_check",
28 |     "clip_outliers_percentile",
29 |     "one_hot",
30 |     "nonempty_mask",
31 |     "safe_log1p",
32 |     "PreprocessConfig",
33 |     "PreprocessBundle",
34 |     "build_features",
35 |     "preprocess_and_save",
36 |     "plot_price_hist_log",
37 |     "plot_min_nights_hist",
38 |     "plot_scatter_map",
39 | ]
40 | 


--------------------------------------------------------------------------------
/src/data_processing.py:
--------------------------------------------------------------------------------
  1 | ﻿import csv
  2 | import subprocess
  3 | import zipfile
  4 | from dataclasses import dataclass
  5 | from pathlib import Path
  6 | from typing import Dict, Iterable, List, Tuple
  7 | 
  8 | import numpy as np
  9 | 
 10 | DATASET_NAME = "dgomonov/new-york-city-airbnb-open-data"
 11 | FILENAME = "AB_NYC_2019.csv"
 12 | 
 13 | KEY_COLUMNS = [
 14 |     "price",
 15 |     "minimum_nights",
 16 |     "number_of_reviews",
 17 |     "reviews_per_month",
 18 |     "calculated_host_listings_count",
 19 |     "availability_365",
 20 |     "latitude",
 21 |     "longitude",
 22 | ]
 23 | 
 24 | 
 25 | def ensure_data_dirs(root: str = "data") -> Dict[str, Path]:
 26 |     base = Path(root)
 27 |     
 28 |     raw = base / "raw"
 29 |     raw.mkdir(parents=True, exist_ok=True)
 30 |     
 31 |     processed = base / "processed"
 32 |     processed.mkdir(parents=True, exist_ok=True)
 33 |     
 34 |     return {"root": base, "raw": raw, "processed": processed}
 35 | 
 36 | 
 37 | def kaggle_download_if_needed(dataset: str, filename: str, out_dir: str) -> Path:
 38 |     out_path = Path(out_dir)
 39 |     out_path.mkdir(parents=True, exist_ok=True)
 40 |     target = out_path / filename
 41 |     if target.exists():
 42 |         return target
 43 | 
 44 |     cmd = [
 45 |         "../.venv/bin/kaggle",
 46 |         "datasets",
 47 |         "download",
 48 |         "-d",
 49 |         dataset,
 50 |         "-p",
 51 |         str(out_path),
 52 |         "--quiet",
 53 |         "--unzip",
 54 |     ]
 55 |     
 56 |     try:
 57 |         # Kaggle CLI cần ~/.kaggle/kaggle.json hoặc biến môi trường KAGGLE_USERNAME/KAGGLE_KEY
 58 |         result = subprocess.run(
 59 |             cmd,
 60 |             check=False,
 61 |             capture_output=True,
 62 |             text=True,
 63 |         )
 64 |     except FileNotFoundError as exc:
 65 |         raise RuntimeError("Không tìm thấy Kaggle CLI") from exc
 66 | 
 67 |     if result.returncode != 0:
 68 |         msg = (result.stderr or result.stdout or "").strip()
 69 |         if not msg:
 70 |             msg = "Không tải được dữ liệu từ Kaggle."
 71 |         if "401" in msg or "403" in msg or "Unauthorized" in msg:
 72 |             raise RuntimeError("Kaggle CLI chưa cấu hình. Kiểm tra kaggle.json hoặc biến môi trường") from None
 73 |         raise RuntimeError(f"Tải từ Kaggle thất bại: {msg}")
 74 | 
 75 |     zip_path = out_path / f"{filename}.zip"
 76 |     if zip_path.exists():
 77 |         with zipfile.ZipFile(zip_path, "r") as zf:
 78 |             zf.extractall(out_path)
 79 |         zip_path.unlink()
 80 | 
 81 |     if not target.exists():
 82 |         raise RuntimeError(f"Tải Kaggle xong nhưng thiếu file {filename}")
 83 |     return target
 84 | 
 85 | 
 86 | def _convert_float(values: Iterable[str]) -> np.ndarray:
 87 |     data = list(values)
 88 |     arr = np.empty(len(data), dtype=np.float64)
 89 |     for idx, raw_val in enumerate(data):
 90 |         val = raw_val.strip()
 91 |         if val == "" or val.upper() == "NA":
 92 |             arr[idx] = np.nan
 93 |         else:
 94 |             arr[idx] = float(val)
 95 |     return arr
 96 | 
 97 | 
 98 | def _convert_int(values: Iterable[str]) -> np.ndarray:
 99 |     data = list(values)
100 |     arr = np.empty(len(data), dtype=np.int64)
101 |     for idx, raw_val in enumerate(data):
102 |         val = raw_val.strip()
103 |         if val == "" or val.upper() == "NA":
104 |             raise ValueError("Giá trị NA xuất hiện ở cột số nguyên.")
105 |         arr[idx] = int(float(val))
106 |     return arr
107 | 
108 | 
109 | def load_airbnb_numpy(csv_path: Path) -> Dict[str, Dict[str, np.ndarray]]:
110 |     with csv_path.open("r", newline="", encoding="utf-8") as handle:
111 |         reader = csv.reader(handle)
112 |         try:
113 |             header = next(reader)
114 |         except StopIteration as exc:
115 |             raise RuntimeError("File CSV trong") from exc
116 |         rows = [row for row in reader]
117 | 
118 |     columns: Dict[str, List[str]] = {col: [] for col in header}
119 |     for row in rows:
120 |         for col, value in zip(header, row):
121 |             columns[col].append(value)
122 | 
123 |     floats = {
124 |         "price",
125 |         "reviews_per_month",
126 |         "latitude",
127 |         "longitude",
128 |     }
129 |     ints = {
130 |         "minimum_nights",
131 |         "number_of_reviews",
132 |         "calculated_host_listings_count",
133 |         "availability_365",
134 |     }
135 | 
136 |     num: Dict[str, np.ndarray] = {}
137 |     text: Dict[str, np.ndarray] = {}
138 | 
139 |     for col, values in columns.items():
140 |         if col in floats:
141 |             num[col] = _convert_float(values)
142 |         elif col in ints:
143 |             num[col] = _convert_int(values)
144 |         else:
145 |             text[col] = np.array(values, dtype=object)
146 | 
147 |     return {"header": header, "text": text, "num": num}
148 | 
149 | 
150 | def _unique_with_sample(arr: np.ndarray, max_samples: int = 4) -> Dict[str, object]:
151 |     if arr.size == 0:
152 |         return {"count": 0, "values": []}
153 |     unique_vals = np.unique(arr)
154 |     sample = unique_vals[:max_samples].tolist()
155 |     return {"count": int(unique_vals.size), "values": sample}
156 | 
157 | 
158 | def basic_checks(data: Dict[str, Dict[str, np.ndarray]]) -> Dict[str, object]:
159 |     header = data["header"]
160 |     num_data = data["num"]
161 |     text_data = data["text"]
162 | 
163 |     if num_data:
164 |         total_rows = len(next(iter(num_data.values())))
165 |     elif text_data:
166 |         total_rows = len(next(iter(text_data.values())))
167 |     else:
168 |         total_rows = 0
169 | 
170 |     neigh = text_data.get("neighbourhood_group", np.array([], dtype=object))
171 |     room = text_data.get("room_type", np.array([], dtype=object))
172 | 
173 |     # availability_365 = số ngày sẵn sàng trong 365 ngày tới
174 |     availability = num_data.get("availability_365", np.array([], dtype=np.int64))
175 |     out_of_range = int(np.sum((availability < 0) | (availability > 365))) if availability.size else 0
176 | 
177 |     rpm = num_data.get("reviews_per_month", np.array([], dtype=np.float64))
178 |     na_rpm = int(np.sum(np.isnan(rpm))) if rpm.size else 0
179 | 
180 |     last_review = text_data.get("last_review", np.array([], dtype=object))
181 |     if last_review.size:
182 |         mask = np.array([str(val).strip() in {"", "NA"} for val in last_review], dtype=bool)
183 |         na_last = int(np.sum(mask))
184 |     else:
185 |         na_last = 0
186 | 
187 |     return {
188 |         "n_rows": total_rows,
189 |         "n_cols": len(header),
190 |         "columns": header,
191 |         "uniq_neigh_group": _unique_with_sample(neigh),
192 |         "uniq_room_type": _unique_with_sample(room),
193 |         "out_of_range_avail": out_of_range,
194 |         "na_reviews_per_month": na_rpm,
195 |         "na_last_review": na_last,
196 |     }
197 | 
198 | 
199 | def load_and_check(root: str = "data") -> Dict[str, object]:
200 |     dirs = ensure_data_dirs(root=root)
201 |     csv_path = dirs["raw"] / FILENAME
202 |     
203 |     if not csv_path.exists():
204 |         kaggle_download_if_needed(
205 |             dataset=DATASET_NAME,
206 |             filename=FILENAME,
207 |             out_dir=str(dirs["raw"]),
208 |         )
209 | 
210 |     data = load_airbnb_numpy(csv_path)
211 |     report = basic_checks(data)
212 | 
213 |     print(f"Shape: {report['n_rows']} hang x {report['n_cols']} cot")
214 |     
215 |     key_cols = [col for col in KEY_COLUMNS if col in report["columns"]]
216 |     print(f"Important Columns: {', '.join(key_cols)}")
217 |     
218 |     neigh = report["uniq_neigh_group"]
219 |     print(f"neighbourhood_group: {neigh['count']} groups -> {', '.join(map(str, neigh['values']))}")
220 |     
221 |     room = report["uniq_room_type"]
222 |     print(f"room_type: {room['count']} types -> {', '.join(map(str, room['values']))}")
223 |     print(f"availability_365 out of [0, 365]: {report['out_of_range_avail']}")
224 |     print(f"reviews_per_month NA: {report['na_reviews_per_month']}")
225 |     print(f"last_review NA: {report['na_last_review']}")
226 | 
227 |     return report
228 | 
229 | 
230 | def clip_outliers_percentile(
231 |     x: np.ndarray, p_low: float = 0.0, p_high: float = 99.5
232 | ) -> Tuple[np.ndarray, float, float]:
233 |     """Clip theo phan tram vi de cat duoi cuc tri."""
234 |     lo, hi = np.percentile(x, [p_low, p_high])
235 |     return np.clip(x, lo, hi), float(lo), float(hi)
236 | 
237 | 
238 | def one_hot(values: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
239 |     """One-hot cho mang object/string, tra ve (matrix, uniques)."""
240 |     uniq, inv = np.unique(values, return_inverse=True)
241 |     oh = np.eye(uniq.size, dtype=np.float64)[inv]
242 |     return oh, uniq
243 | 
244 | 
245 | def nonempty_mask(arr_obj: np.ndarray) -> np.ndarray:
246 |     """True neu text khong rong hoac la 'NA'."""
247 |     return np.array([str(v).strip() not in {"", "NA"} for v in arr_obj], dtype=bool)
248 | 
249 | 
250 | def safe_log1p(x: np.ndarray) -> np.ndarray:
251 |     """log1p an toan cho gia tri khong am."""
252 |     x = np.maximum(x, 0.0)
253 |     return np.log1p(x)
254 | 
255 | 
256 | @dataclass
257 | class PreprocessConfig:
258 |     p_high_min_nights: float = 99.0
259 |     p_high_host_listings: float = 99.0
260 |     host_big_threshold: float = 3.0
261 | 
262 | 
263 | @dataclass
264 | class PreprocessBundle:
265 |     X: np.ndarray
266 |     y: np.ndarray
267 |     y_log1p: np.ndarray
268 |     feature_names: np.ndarray
269 |     room_type_uniques: np.ndarray
270 |     neigh_group_uniques: np.ndarray
271 | 
272 | 
273 | def build_features(
274 |     num: Dict[str, np.ndarray],
275 |     txt: Dict[str, np.ndarray],
276 |     cfg: PreprocessConfig = PreprocessConfig(),
277 | ) -> PreprocessBundle:
278 |     """Build tap dac trung NumPy-only tu dict cot so/text."""
279 |     price = num["price"].astype(np.float64)
280 |     minimum_nights = num["minimum_nights"].astype(np.float64)
281 |     number_of_reviews = num["number_of_reviews"].astype(np.float64)
282 |     host_listings = num["calculated_host_listings_count"].astype(np.float64)
283 |     availability_365 = np.clip(num["availability_365"].astype(np.float64), 0, 365)
284 |     reviews_per_month = num["reviews_per_month"].astype(np.float64)
285 | 
286 |     room_type = txt["room_type"]
287 |     neigh_group = txt["neighbourhood_group"]
288 |     last_review = txt["last_review"]
289 | 
290 |     rpm_filled = reviews_per_month.copy()
291 |     rpm_filled[np.isnan(rpm_filled)] = 0.0
292 | 
293 |     min_nights_clip, _, _ = clip_outliers_percentile(
294 |         minimum_nights, 0.0, cfg.p_high_min_nights
295 |     )
296 |     host_listings_clip, _, _ = clip_outliers_percentile(
297 |         host_listings, 0.0, cfg.p_high_host_listings
298 |     )
299 | 
300 |     has_last_review = nonempty_mask(last_review).astype(np.float64)
301 |     is_entire_home = (room_type == "Entire home/apt").astype(np.float64)
302 |     host_is_big = (host_listings_clip >= cfg.host_big_threshold).astype(np.float64)
303 | 
304 |     oh_room, rt_uniques = one_hot(room_type)
305 |     oh_neigh, ng_uniques = one_hot(neigh_group)
306 | 
307 |     X_blocks = [
308 |         safe_log1p(number_of_reviews).reshape(-1, 1),
309 |         safe_log1p(min_nights_clip).reshape(-1, 1),
310 |         safe_log1p(host_listings_clip).reshape(-1, 1),
311 |         (availability_365 / 365.0).reshape(-1, 1),
312 |         safe_log1p(rpm_filled).reshape(-1, 1),
313 |         is_entire_home.reshape(-1, 1),
314 |         host_is_big.reshape(-1, 1),
315 |         has_last_review.reshape(-1, 1),
316 |         oh_room,
317 |         oh_neigh,
318 |     ]
319 |     X = np.concatenate(X_blocks, axis=1)
320 |     y = price.copy()
321 |     y_log1p = safe_log1p(y)
322 | 
323 |     feature_names = [
324 |         "log1p_num_reviews",
325 |         "log1p_minimum_nights",
326 |         "log1p_host_listings",
327 |         "days_available_ratio",
328 |         "log1p_reviews_per_month",
329 |         "is_entire_home",
330 |         "host_is_big_ge3",
331 |         "has_last_review",
332 |     ] + [f"rt::{s}" for s in rt_uniques.tolist()] + [
333 |         f"ng::{s}" for s in ng_uniques.tolist()
334 |     ]
335 | 
336 |     return PreprocessBundle(
337 |         X=X,
338 |         y=y,
339 |         y_log1p=y_log1p,
340 |         feature_names=np.array(feature_names, dtype=object),
341 |         room_type_uniques=rt_uniques.astype(object),
342 |         neigh_group_uniques=ng_uniques.astype(object),
343 |     )
344 | 
345 | 
346 | def preprocess_and_save(
347 |     root: str = "data",
348 |     out_name: str = "airbnb_2019_preprocessed.npz",
349 |     cfg: PreprocessConfig = PreprocessConfig(),
350 | ) -> Path:
351 |     """End-to-end: load CSV tho, build features, luu npz."""
352 |     dirs = ensure_data_dirs(root=root)
353 |     csv_path = dirs["raw"] / FILENAME
354 |     if not csv_path.exists():
355 |         kaggle_download_if_needed(
356 |             dataset=DATASET_NAME, filename=FILENAME, out_dir=str(dirs["raw"])
357 |         )
358 |     data = load_airbnb_numpy(csv_path)
359 |     bundle = build_features(data["num"], data["text"], cfg)
360 | 
361 |     out_path = dirs["processed"] / out_name
362 |     np.savez_compressed(
363 |         out_path,
364 |         X=bundle.X,
365 |         y=bundle.y,
366 |         y_log1p=bundle.y_log1p,
367 |         feature_names=bundle.feature_names,
368 |         room_type_uniques=bundle.room_type_uniques,
369 |         neigh_group_uniques=bundle.neigh_group_uniques,
370 |     )
371 |     return out_path
372 | 
373 | 
374 | if __name__ == "__main__":
375 |     load_and_check()
376 | 


--------------------------------------------------------------------------------
/src/models.py:
--------------------------------------------------------------------------------
 1 | from typing import Iterator, Tuple
 2 | 
 3 | import numpy as np
 4 | 
 5 | 
 6 | class StandardScaler:
 7 |     """Chuan hoa z-score thuong dung."""
 8 | 
 9 |     def __init__(self) -> None:
10 |         self.mean_: np.ndarray | None = None
11 |         self.std_: np.ndarray | None = None
12 | 
13 |     def fit(self, X: np.ndarray) -> "StandardScaler":
14 |         self.mean_ = X.mean(axis=0)
15 |         self.std_ = X.std(axis=0) + 1e-12
16 |         return self
17 | 
18 |     def transform(self, X: np.ndarray) -> np.ndarray:
19 |         if self.mean_ is None or self.std_ is None:
20 |             msg = "StandardScaler must be fitted before transform."
21 |             raise RuntimeError(msg)
22 |         return (X - self.mean_) / self.std_
23 | 
24 |     def fit_transform(self, X: np.ndarray) -> np.ndarray:
25 |         return self.fit(X).transform(X)
26 | 
27 | 
28 | class LinearReg:
29 |     """Linear regression don gian: nghiem dong hoac gradient descent."""
30 | 
31 |     def __init__(self, l2: float = 0.0, lr: float | None = None, epochs: int = 0) -> None:
32 |         self.l2 = float(l2)
33 |         self.lr = lr
34 |         self.epochs = int(epochs)
35 |         self.w_: np.ndarray | None = None
36 | 
37 |     def fit_normal(self, X: np.ndarray, y: np.ndarray) -> "LinearReg":
38 |         n, d = X.shape
39 |         del n  # not used in closed form
40 |         A = X.T @ X + self.l2 * np.eye(d)
41 |         b = X.T @ y
42 |         self.w_ = np.linalg.solve(A, b)
43 |         return self
44 | 
45 |     def fit_gd(self, X: np.ndarray, y: np.ndarray) -> "LinearReg":
46 |         n, d = X.shape
47 |         lr = self.lr or 1e-2
48 |         w = np.zeros(d, dtype=np.float64)
49 |         for _ in range(self.epochs or 1000):
50 |             r = X @ w - y
51 |             grad = (X.T @ r) / n + self.l2 * w
52 |             w -= lr * grad
53 |         self.w_ = w
54 |         return self
55 | 
56 |     def predict(self, X: np.ndarray) -> np.ndarray:
57 |         if self.w_ is None:
58 |             msg = "LinearReg must be fitted before predict."
59 |             raise RuntimeError(msg)
60 |         return X @ self.w_
61 | 
62 | 
63 | def rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:
64 |     err = y_true - y_pred
65 |     return float(np.sqrt(np.mean(err * err)))
66 | 
67 | 
68 | def mae(y_true: np.ndarray, y_pred: np.ndarray) -> float:
69 |     return float(np.mean(np.abs(y_true - y_pred)))
70 | 
71 | 
72 | class KFold:
73 |     """Chia K-fold thuong dung, ho tro shuffle."""
74 | 
75 |     def __init__(self, n_splits: int = 5, shuffle: bool = True, seed: int = 42) -> None:
76 |         self.k = int(n_splits)
77 |         self.shuffle = bool(shuffle)
78 |         self.seed = int(seed)
79 | 
80 |     def split(self, n_samples: int) -> Iterator[Tuple[np.ndarray, np.ndarray]]:
81 |         idx = np.arange(n_samples)
82 |         if self.shuffle:
83 |             rng = np.random.default_rng(self.seed)
84 |             rng.shuffle(idx)
85 |         folds = np.array_split(idx, self.k)
86 |         for i in range(self.k):
87 |             val_idx = folds[i]
88 |             if self.k > 1:
89 |                 train_idx = np.concatenate([folds[j] for j in range(self.k) if j != i])
90 |             else:
91 |                 train_idx = idx
92 |             yield train_idx, val_idx
93 | 


--------------------------------------------------------------------------------
/src/visualization.py:
--------------------------------------------------------------------------------
 1 | import numpy as np
 2 | 
 3 | 
 4 | def _plt():
 5 |     """Late import matplotlib to avoid hard dependency during pure preprocessing."""
 6 |     from matplotlib import pyplot as plt  # type: ignore import-error
 7 | 
 8 |     return plt
 9 | 
10 | 
11 | def plot_price_hist_log(price: np.ndarray) -> None:
12 |     """Histogram gia tren thang log; clip tren 99.5%."""
13 |     plt = _plt()
14 |     mask = np.isfinite(price) & (price > 0)
15 |     price = price[mask]
16 |     if price.size == 0:
17 |         return
18 |     hi = np.percentile(price, 99.5)
19 |     bins = np.logspace(
20 |         np.log10(max(price.min(), 1e-6)),
21 |         np.log10(max(hi, 1e-6)),
22 |         40,
23 |     )
24 |     plt.figure()
25 |     plt.hist(np.clip(price, None, hi), bins=bins, edgecolor="none")
26 |     plt.xscale("log")
27 |     plt.xlabel("price (log scale)")
28 |     plt.ylabel("count")
29 |     plt.title("Phan phoi gia (log)")
30 |     plt.tight_layout()
31 |     plt.show()
32 | 
33 | 
34 | def plot_min_nights_hist(min_nights: np.ndarray) -> None:
35 |     """Histogram minimum_nights (clip 99%)."""
36 |     plt = _plt()
37 |     mn = min_nights[np.isfinite(min_nights)]
38 |     if mn.size == 0:
39 |         return
40 |     hi = np.percentile(mn, 99.0)
41 |     plt.figure()
42 |     plt.hist(np.clip(mn, None, hi), bins=40, edgecolor="none")
43 |     plt.xlabel("minimum_nights (clipped 99%)")
44 |     plt.ylabel("count")
45 |     plt.title("Phan phoi minimum_nights")
46 |     plt.tight_layout()
47 |     plt.show()
48 | 
49 | 
50 | def plot_scatter_map(lon: np.ndarray, lat: np.ndarray, neigh_group: np.ndarray) -> None:
51 |     """Scatter theo toa do, to mau theo neighbourhood_group."""
52 |     plt = _plt()
53 |     ok = np.isfinite(lon) & np.isfinite(lat)
54 |     lon, lat = lon[ok], lat[ok]
55 |     ng = neigh_group[ok]
56 |     if lon.size == 0:
57 |         return
58 |     groups, inv = np.unique(ng, return_inverse=True)
59 |     plt.figure()
60 |     sc = plt.scatter(lon, lat, c=inv, s=4, alpha=0.5, cmap="tab10")
61 |     plt.xlabel("longitude")
62 |     plt.ylabel("latitude")
63 |     plt.title("Diem cho thue theo khu")
64 |     cbar = plt.colorbar(sc, ticks=np.arange(groups.size))
65 |     cbar.ax.set_yticklabels(groups.tolist())
66 |     plt.tight_layout()
67 |     plt.show()
68 | 


--------------------------------------------------------------------------------